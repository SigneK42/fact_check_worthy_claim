{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "\n",
    "# Caching stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from fact_classification import *\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_crowdsourced, df_ground_truth = data_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Speaker_title</th>\n",
       "      <th>Speaker_party</th>\n",
       "      <th>File_id</th>\n",
       "      <th>Length</th>\n",
       "      <th>Line_number</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>I think we've seen a deterioration of values.</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>I think for a while as a nation we condoned th...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.456018</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>For a while, as I recall, it even seems to me ...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.805547</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>So we've seen a deterioration in values, and o...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>0.698942</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>We got away, we got into this feeling that val...</td>\n",
       "      <td>George Bush</td>\n",
       "      <td>Vice President</td>\n",
       "      <td>REPUBLICAN</td>\n",
       "      <td>1988-09-25.txt</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  \\\n",
       "0           16      I think we've seen a deterioration of values.   \n",
       "1           17  I think for a while as a nation we condoned th...   \n",
       "2           18  For a while, as I recall, it even seems to me ...   \n",
       "3           19  So we've seen a deterioration in values, and o...   \n",
       "4           20  We got away, we got into this feeling that val...   \n",
       "\n",
       "       Speaker   Speaker_title Speaker_party         File_id  Length  \\\n",
       "0  George Bush  Vice President    REPUBLICAN  1988-09-25.txt       8   \n",
       "1  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      16   \n",
       "2  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      29   \n",
       "3  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      35   \n",
       "4  George Bush  Vice President    REPUBLICAN  1988-09-25.txt      15   \n",
       "\n",
       "   Line_number  Sentiment  Verdict  \n",
       "0           16   0.000000       -1  \n",
       "1           17  -0.456018       -1  \n",
       "2           18  -0.805547       -1  \n",
       "3           19   0.698942       -1  \n",
       "4           20   0.000000       -1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing stemming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming will be good as it removes some variability in how words are stated. But we should prooobably also try without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_stemmed'] = stem(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['i', 'think', \"we'v\", 'seen', 'a', 'deterior'...\n",
       "1       ['i', 'think', 'for', 'a', 'while', 'as', 'a',...\n",
       "2       ['for', 'a', 'while,', 'as', 'i', 'recall,', '...\n",
       "3       ['so', \"we'v\", 'seen', 'a', 'deterior', 'in', ...\n",
       "4       ['we', 'got', 'away,', 'we', 'got', 'into', 't...\n",
       "                              ...                        \n",
       "1027    ['he', 'ha', 'promis', 'a', 'trillion', 'dolla...\n",
       "1028    ['(laughter)', 'i', '--', \"there'\", 'an', 'old...\n",
       "1029             ['well,', 'can', 'i', 'answer', 'that?']\n",
       "1030    ['i', 'look', 'forward', 'to', 'the', 'final',...\n",
       "1031    ['for', 'those', 'of', 'you', 'for', 'me,', 't...\n",
       "Name: Text_stemmed, Length: 23533, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text_stemmed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into test and train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the description of the task we shuold split the dataset into test and train based on year of debate. All debates before and including 2008 goes into train and more recent debates into test. (I would also consider making a validation set when we get closer to the end to have a final validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = test_train_split(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the tfid matrix for the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfid, test_tfid=  tfid(train = df_train.Text, test = df_test.Text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18170x10641 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 277846 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5363x10641 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 70684 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, I first fitted the vectorizer to the train set (so only words in the train set will be counted) and then transformed the test set using the same vectorizer. They have the same amount of columns which indicate it has been done correctly, keeping them sparse to save storage."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using standard models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(\n",
    "        n_estimators=20,\n",
    "        max_depth=20,\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced_subsample\",\n",
    "    )\n",
    "\n",
    "The base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train, pred_test = predict_it(train_tfid, df_train.Verdict, test_tfid) # predicting with basemodel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of our base-model is ok, it is important to also consider the scores for individual classes because our data is so unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = score_it(df_test.Verdict, pred_test, df_train.Verdict, pred_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple randomforrestclassifier based only on the text stemmed and vectorized gives an accuracy of 64 percent. This will be our base line model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proving the point of checking more than one accuracy measure and your data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a model which will have a high score but be completely useless. We can predict all -1 and ger an average weighted fscore of nearly 50%..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = stupid_model(df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\signe\\anaconda3\\envs\\model\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\signe\\anaconda3\\envs\\model\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alogrithm</th>\n",
       "      <th>features</th>\n",
       "      <th>p_NFS</th>\n",
       "      <th>p_UFS</th>\n",
       "      <th>p_CFS</th>\n",
       "      <th>p_wavg</th>\n",
       "      <th>r_NFS</th>\n",
       "      <th>r_UFS</th>\n",
       "      <th>r_CFS</th>\n",
       "      <th>r_wavg</th>\n",
       "      <th>f_NFS</th>\n",
       "      <th>f_UFS</th>\n",
       "      <th>f_CFS</th>\n",
       "      <th>f_wavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForrestClassifier</td>\n",
       "      <td>tfid</td>\n",
       "      <td>0.787743</td>\n",
       "      <td>0.287819</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.691448</td>\n",
       "      <td>0.795112</td>\n",
       "      <td>0.470305</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.666045</td>\n",
       "      <td>0.791410</td>\n",
       "      <td>0.357099</td>\n",
       "      <td>0.530915</td>\n",
       "      <td>0.671693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stupid_model</td>\n",
       "      <td>none</td>\n",
       "      <td>0.617938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.381847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.617938</td>\n",
       "      <td>0.763858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 alogrithm features     p_NFS     p_UFS  p_CFS    p_wavg  \\\n",
       "0  RandomForrestClassifier     tfid  0.787743  0.287819  0.644  0.691448   \n",
       "0             stupid_model     none  0.617938  0.000000  0.000  0.381847   \n",
       "\n",
       "      r_NFS     r_UFS     r_CFS    r_wavg     f_NFS     f_UFS     f_CFS  \\\n",
       "0  0.795112  0.470305  0.451613  0.666045  0.791410  0.357099  0.530915   \n",
       "0  1.000000  0.000000  0.000000  0.617938  0.763858  0.000000  0.000000   \n",
       "\n",
       "     f_wavg  \n",
       "0  0.671693  \n",
       "0  0.472017  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df_score, score_it(df_test.Verdict, pred_test, df_train.Verdict, pred_train, algorithm = 'stupid_model', features = 'none')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f1af3359ee966fa549b9342c95a66c864e02d3c200665f3410ce643c369b44e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
