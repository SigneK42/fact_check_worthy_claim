{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:27:39.823816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_crowdsourced, df_ground_truth = data_loading(local=True)\n",
    "df['Sentiment'] = df.Sentiment.fillna(df.Sentiment[df.Verdict == -1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features\n",
    "Load the features matrix that we generated in the `feature_generation.ipynb` notebook. This is a large sparse matrix so ww convert it to Compressed Sparse Row (CSR) format to avoid running out of memory when fitting our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open('../results/df_features.bz2') as f:\n",
    "    df_features = pickle.load(f)\n",
    "\n",
    "# Convert to compressed sparse row matrix\n",
    "X = sp.sparse.csr_matrix(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and generate indexes\n",
    "\n",
    "We split the dataset according to the instructions in the assignment, where data up until and including year 2008 will be used for training, and data after 2008 will be used for testing. Here we also generate indexes for the various feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, idx_train = test_train_split(df)\n",
    "\n",
    "y = df['Verdict']\n",
    "y_train = df_train['Verdict']\n",
    "y_test = df_test['Verdict']\n",
    "\n",
    "X_train = X[idx_train]\n",
    "X_test = X[~idx_train]\n",
    "\n",
    "# Column index for the numeric columns Sentiment and Length\n",
    "col_idx_n = (df_features.columns == 'Sentiment') | (df_features.columns == 'Length')\n",
    "\n",
    "# Column index for TF-IDF features on the raw Text column with n-grams=1\n",
    "col_idx_w1 = df_features.columns.str.startswith('W1_')\n",
    "\n",
    "# Column index for TF-IDF features on the raw Text column with n-grams=2\n",
    "col_idx_w2 = df_features.columns.str.startswith('W2_')\n",
    "\n",
    "# Column index for TF-IDF features on the stemmed text with n-grams=1\n",
    "col_idx_ws = df_features.columns.str.startswith('WS_')\n",
    "\n",
    "# Column index for POS features\n",
    "col_idx_p = df_features.columns.str.startswith('P_')\n",
    "\n",
    "# Column index for NER labels\n",
    "col_idx_e = df_features.columns.str.startswith('E_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "url = \"https://zenodo.org/record/3609356/files/crowdsourced.csv?download=1\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: Tokenize and pad the sequences\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df[\"Text\"])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_df[\"Text\"])\n",
    "X_test = tokenizer.texts_to_sequences(test_df[\"Text\"])\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=256, padding=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=256, padding=\"post\")\n",
    "\n",
    "y_train = train_df[\"Verdict\"]\n",
    "y_test = test_df[\"Verdict\"]\n",
    "\n",
    "# Define the Keras LSTM model\n",
    "def create_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=256))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Instantiate and train the Keras LSTM classifier\n",
    "lstm_classifier = KerasClassifier(build_fn=create_lstm_model, epochs=5, batch_size=64)\n",
    "lstm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier\n",
    "y_pred = lstm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact_check",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
