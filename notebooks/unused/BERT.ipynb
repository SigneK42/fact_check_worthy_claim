{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tor/anaconda3/envs/fact_check/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-18 10:11:55.095290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertForSequenceClassification: ['vocab_transform.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'vocab_transform.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.5.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.1.attention.self.value.bias', 'classifier.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'pooler.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'classifier.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/tor/anaconda3/envs/fact_check/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 18000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3375\n",
      "  Number of trainable parameters = 109484547\n",
      "/tmp/ipykernel_990/2172970034.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1126' max='3375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1126/3375 2:02:04 < 4:04:16, 0.15 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='281' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [281/282 09:43 < 00:02, 0.48 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/tmp/ipykernel_990/2172970034.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "/tmp/ipykernel_990/2172970034.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4501\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4501\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "/tmp/ipykernel_990/2172970034.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "/tmp/ipykernel_990/2172970034.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4501\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "/tmp/ipykernel_990/2172970034.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "/tmp/ipykernel_990/2172970034.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4501\n",
      "  Batch size = 16\n",
      "***** Running Prediction *****\n",
      "  Num examples = 4501\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='281' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [281/282 09:42 < 00:02, 0.48 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.61%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.92      0.86      2926\n",
      "           0       0.00      0.00      0.00       502\n",
      "           1       0.61      0.66      0.64      1073\n",
      "\n",
      "    accuracy                           0.76      4501\n",
      "   macro avg       0.47      0.53      0.50      4501\n",
      "weighted avg       0.67      0.76      0.71      4501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tor/anaconda3/envs/fact_check/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tor/anaconda3/envs/fact_check/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tor/anaconda3/envs/fact_check/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://zenodo.org/record/3609356/files/crowdsourced.csv?download=1\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: Tokenize using the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_and_encode(texts):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "X_train = tokenize_and_encode(train_df[\"Text\"].tolist())\n",
    "X_test = tokenize_and_encode(test_df[\"Text\"].tolist())\n",
    "\n",
    "y_train = torch.tensor(train_df[\"Verdict\"].tolist()).add(1)  # Add 1 to shift labels from [-1, 0, 1] to [0, 1, 2]\n",
    "y_test = torch.tensor(test_df[\"Verdict\"].tolist()).add(1)\n",
    "\n",
    "# Create a PyTorch dataset\n",
    "class CrowdsourcedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = CrowdsourcedDataset(X_train, y_train)\n",
    "test_dataset = CrowdsourcedDataset(X_test, y_test)\n",
    "\n",
    "# Instantiate the BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Define the Trainer and TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train the BERT classifier\n",
    "trainer.train()\n",
    "\n",
    "# Test and evaluate the classifier\n",
    "y_pred = trainer.predict(test_dataset).predictions.argmax(axis=-1)\n",
    "\n",
    "# Shift labels back to original range [-1, 0, 1]\n",
    "y_pred = y_pred - 1\n",
    "y_test = y_test - 1\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fact_check",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
